\section{Разработка алгоритма}

\subsection{Постановка задач}

На сегодняшний день двумя популярными методами для распределения нейронных сетей являются распределение модели и данных.
При распределении модели слои нейронной сети располагаются на нескольких компьютерах и входные данные сначала проходят 
через все слои на первом компьютере, далее результат отправляется на обработку последующим слоям на втором компьютере 
и так происходит, пока данные не пройдут через всю сеть. В методе распределения данных весь набор входных данных разбивается 
на части, и после каждая из этих частей отправляется на обработку определенному компьютеру, где уже запущена полная модель.
Метод распределения модели чаще применяется в случаях, когда размер памяти, занимаемой моделью превышает количество памяти 
на одной машине. Отрицательным следствием этого метода является увеличение нагрузки на сеть, так как один элемент из входного 
набор данных будет приводить к нескольким обменам результатов между слоями нейронной сети. Метод распределения данных 
оказывает меньшую нагрузку на сеть, так как каждая часть единожды отправляется на обработку. 

В данной работе будет использоваться метод распределения данных по нескольким причинам. Во-первых, при использовании метода 
распределения модели намного сложнее применять уже разработанные методы. Во-вторых, видеоизображения хорошо ложатся на метод 
распределения данных, так как видео представляет из себя набор кадров (изображений), каждый из которых может обрабатываться 
независимо от других. На рисунке \ref{general_algo} представлен принцип работы алгоритма в общем виде. Как можно понять из 
рисунка, алгоритм будет состоять из двух основных компонентов: планировщик и рабочий. Планировщик будет получать на вход 
видеофайл, разбивать его на кадры и далее отправлять кадры рабочим по определенному алгоритму планирования. Рабочий будет 
принимать кадр, применять метод распознавания объектов и отправлять список результатов обратно планировщику. Каждый 
результат будет представлять собой координаты ограничивающей рамки и идентификатор класса объекта. Затем планировщик будет 
отображать результаты и сохранять кадры в правильном порядке в выходное видео. 

\addimg{general_algo}{0.55}{Принцип работы алгоритма в общем виде}{general_algo}

После того, как определились с общим принципом работы алгоритма, можно переходить к его реализации. Для этого поставим 
следующие задачи, которые нужно решить:

\begin{enumerate}
\item выбрать библиотеку, которая позволяет запускать разработанные методы для распознавания объектов на изображениях;
\item определить алгоритм планирования, согласно которому планировщик будет отправлять кадры рабочим;
\item разработать алгоритм для сохранения кадров в правильном порядке и учесть возможные потери кадров;
\item выбрать протокол транспортного уровня, посредством которого планировщик и рабочие будут обмениваться сообщениями;
\item определить формат сообщений для взаимодействия между планировщиком и рабочими.
\end{enumerate}

\subsection{Основные компоненты}

\subsubsection{Рабочий}

В первой главе было установлено, что на данный момент самыми эффективными методами для распознавания объектов на изображениях
являются одношаговые методы YOLO. При реализации данных методов авторы используют фреймворк Darknet, который реализован с 
поддержкой платформы CUDA \cite{DARKNET}. Платформа CUDA разработана компанией Nvidia, которая позволяет выполнять отдельные
части программы на GPU, произведенных этой же компанией. Так как в данной работе рассматриваются КОВР, которые чаще всего 
не имеют GPU, то использование фреймворка Darknet выглядит нецелесообразным. Помимо этого, по заверению самих разработчиков, они 
больше стремились оптимизировать свой фреймворк под работу с GPU, нежели с CPU. Данный тезис также подтверждается тестами, 
которые были проведены автором этой работы, что даже при сборки Darknet с библиотекой OpenMP, время работы при использовании 
только CPU оказывается больше, чем у альтернативных реализаций.

Структура разработанных моделей YOLO хранится в текстовом файле, формат которого заранее определен. Это позволяет реализовать модели, 
используя другие библиотеки. При изучении репозитория с реализацией метода YOLOv4, были найдены комментарии авторов, где утверждалось, 
что на данный момент самой лучшей реализацией их метода на CPU является реализация из библиотеки OpenCV \cite{YOLO4_IMPL}. 
Open Source Computer Vision Library (OpenCV) библиотека изначально разработанная компанией Intel для обработки изображений 
и решения различных задач компьютерного зрения. Использование библиотеки OpenCV дает следующие преимущества:

\begin{enumerate}
\item возможность загружать модели из разных форматов. На данный момент поддерживаются форматы всех популярных библиотек: 
PyTorch, Tensorflow, Caffe и Darknet. Также можно загружать модель из файлов формата ONNX, данный формат призван 
унифицировать представление моделей между разными библиотеками для машинного обучения;
\item при выполнении вычислений на CPU, будут использоваться поддерживаемые процессором SIMD инструкции. То есть для процессоров 
архитектуры x86 это будет набор инструкций SSE и AVX, для процессоров архитектуры ARM соответственно NEON;
\item поддержка интеграции с библиотекой Tengine Lite. Данная библиотека разрабатывалась специально под КОВР и оптимизирует
часто используемые операции (например, операция свертки) за счет использования SIMD инструкций, что приводит 
к уменьшению времени работы модели;
\item при наличии GPU можно полностью перенести на нее все вычисления, указав это при конфигурации. Также есть возможность 
указать фреймворк OpenCL, который позволяет задействовать CPU и GPU на гетерогенных платформах.
\end{enumerate}

Учитывая все приведенные выше преимущества был сделан выбор именно в сторону библиотеки OpenCV. Исходный код детектора 
для распознавания объектов на изображениях на языке Python приведен в приложении \hyperlink{a-app}{А}.

\subsubsection{Планировщик}

\textbf{Алгоритм планирования}

Обычно узлы кластера имеют одинаковые вычислительные ресурсы, поэтому должны быть нагружены одинаково. В нашем случае 
используется гомогенный кластер, в связи c этим был выбран алгоритм планирования Round-Robin. В данном алгоритме рабочие
упорядочиваются в циклический список и после планировщик начинает проходить по этому списку, пока есть задачи на выполнение.

\textbf{Алгоритм сохранения кадров}

Поскольку время распознавания объектов на кадре в общем случае неопределенно, то могут возникать ситуации, когда последующий кадр
будет обработан раньше предыдущего. Также нужно учесть, что в процессе обработки видео несколько рабочих могут выйти из 
строя и не завершить обработку отправленного им кадра. При возникновении таких ситуаций можно поступить двумя способами:
отправить данный кадр другому рабочему или отбросить его. В нашем случае будем учитывать, что выход из строя рабочего это
исключительная ситуация, которая происходит в редких случаях. А так как типичное видео имеет частоту кадров порядка 30 кадров
в секунду и более, то потери единичных кадров не критичны, поэтому при отказе рабочего была выбрана
стратегия отброса последнего отправленного ему кадра.

На рисунке \ref{collector_algo} изображена блок-схема разработанного алгоритма, полная реализация на языке Python 
представлена в приложении \hyperlink{b-app}{Б}. Рассмотрим алгоритм подробнее:

\begin{enumerate}
\item буфер полученных кадров \emph{rcvd\_buf} основан на структуре данных очередь с приоритетом. В качестве приоритета 
используется порядковый номер кадра, поэтому в голове очереди всегда находится самый ранний из полученных кадров. Размер 
очереди ограничен параметром \emph{max\_size}, который задается при старте планировщика. С учетом этого получаем, что 
операции вставки и удаления минимального элемента из очереди будут иметь асимптотическую сложность \emph{O(log[max\_size])};
\item переменная \emph{last\_written} содержит в себе порядковый номер кадра, который был записан последним;
\item таймаут на получение кадра указывается при старте планировщика и будет зависеть от среднего времени 
обработки кадра одним рабочим;
\item планировщик старается сохранять кадры в правильном порядке, но если размер буфера \emph{rcvd\_buf} превышает
максимальное значение, тогда следующим будет записан самый ранний кадр, который есть на данный момент в буфере. Даже 
если позже от рабочего вернется недостающий кадр -- он будет отброшен.
\end{enumerate}

\addimg{collector_algo}{0.6}{Алгоритм сохранения кадров}{collector_algo}

\subsection{Взаимодействие между компонентами}

\subsubsection{Транспорт}

При выборе транспортного протокола главным требованием было возможность обмениваться атомарными сообщениями между узлами
кластера. Это можно реализовать несколькими способами. Во-первых, можно взять протокол транспортного уровня (TCP, UDP)
и поверх него реализовать протокол обмена сообщениями. Преимущество такого подхода, что мы можем гибче настраивать разработанный
протокол под свои требования. Вполне очевидным недостатком данного подхода являются большие временные издержки необходимые 
для разработки, поэтому такой подход был отклонен. Во-вторых, можно использовать один из известных брокеров сообщений, 
которые уже имеют свой внутренний протокол. Недостатком такого подхода являются усложнение процесса развертывания 
приложения и необходимости дополнительных ресурсов для брокера сообщений. В-третьих, можно использовать уже готовую 
библиотеку для обмена сообщениями такую, как ZeroMQ и именно этот вариант был выбран.

ZeroMQ -- это легковесная библиотека для обмена атомарными сообщениями, посредством использования предоставляемых сокетов 
\cite{ZEROMQ}. Данная библиотека имеет более 10 типов сокетов, используя которые можно реализовывать разные топологии.
Рассмотрим подробнее разработанную топологию на рисунке \ref{zeromq_topo}:

\addimg{zeromq_topo}{0.5}{Топология подключения планировщика и рабочих}{zeromq_topo}

\begin{enumerate}
\item через \emph{PUSH} сокет планировщика рабочим отправляются прочитанные кадры. При подключении нескольких клиентов к 
\emph{PUSH} сокету сообщения им отправляются согласно алгоритму Round-Robin;
\item рабочий при старте начинает слушать сообщения со своего \emph{PULL} сокета, который подключен к \emph{PUSH} сокету 
планировщика;
\item результаты распознавания рабочий отправляет через свой \emph{PUSH} сокет, который подключен к \emph{PULL} сокету 
планировщика;
\item планировщик слушает свой \emph{PULL} сокет и при поступлении результата помещает его буфер, откуда после результаты
обрабатываются согласно алгоритму сохранения кадров.
\end{enumerate}

Также стоит упомянуть, что преимуществом разработанной топологии является возможность добавлять рабочих прямо в процессе 
обработки видео. Такое происходит из-за встроенного механизма обнаружения подключенных клиентов в ZeroMQ, то есть в 
протокол не нужно добавлять служебные сообщения для обнаружения новых рабочих. 

\subsubsection{Формат сообщений}

Для взаимодействия между планировщиком и рабочими были определены два вида сообщений: запрос на распознавание и результат
распознавания. Сам формат сообщений бинарный, порядок байт -- big-endian.

На рисунке \ref{proto_req} представлена структура сообщения с запросом на распознавание. Поле \emph{ID} хранит в себе
порядковый номер отправляемого кадра, которое после добавляется в сообщение с результатом. В поле \emph{Frame Data} 
содержится непосредственно передаваемый кадр с размерами $(Height \times Width \times Channels)$.

\addimg{proto_req}{0.6}{Структура сообщения с запросом на распознавание}{proto_req}

На рисунке \ref{proto_resp} представлена структура сообщения с результатом распознавания. Как ранее упоминалось, 
поле \emph{ID} содержит в себе порядковый номер кадра. Поле \emph{Detection Time} представляет собой количество секунд,
потраченных на обработку данного кадра, это значение далее используется планировщиком для сбора статистики. Так как
на одном кадре может быть более одного объекта, то поле \emph{Length} хранит в себе количество распознанных объектов.
\emph{Detection Results} представляет собой массив результатов.

\addimg{proto_resp}{0.65}{Структура сообщения с результатом распознавания}{proto_resp}

На рисунке \ref{proto_result} представлена структура одного элемента из массива \emph{Detection Results}. Координаты
\emph{(X1, Y1)} представляют собой координаты левого-верхнего угла ограничивающей рамки, а координаты \emph{(X2, Y2)} -- 
правого-нижнего угла. Значение \emph{Score} является вероятностью того, что внутри ограничивающей рамки есть объект, 
и он относится к классу с идентификатором \emph{Class ID}.

\addimg{proto_result}{0.65}{Структура результата распознавания}{proto_result}

\subsection{Описание разработанного алгоритма}

Поскольку основные задачи планировщика больше связаны с вводом-выводом, нежели с какими-то CPU интенсивными задачами, 
то было принято решение при его реализации использовать пакет asyncio из стандартной библиотеки языка Python. На рисунке
\ref{frame_seq} представлена диаграмма последовательности обработки одного кадра. Планировщик при старте запускает три 
корутины \emph{Reader}, \emph{DetectionPoller} и \emph{Writer}. Так как скорость чтения кадров будет явно больше скорости
распознавания объектов, поэтому скорость чтения контролируется размером \emph{ReadBuffer}, при заполнении которого корутина
\emph{Reader} будет заблокирована. Аналогичным образом устроен \emph{WriteBuffer}, при заполнении которого корутина 
\emph{DetectionPoller} заблокируется. Рассмотрим последовательность обработки кадра подробнее:

\addimg{frame_seq}{0.9}{Диаграмма последовательности обработки одного кадра}{frame_seq}

\begin{enumerate}
\item для разбиения входного видео на кадры также используется библиотека OpenCV. Поскольку данная библиотека не 
приспособлена для работы с asyncio, то был реализован класс \emph{AsyncFrameReader}, который вызывает метод чтения 
кадра в другом потоке, тем самым не блокируя поток событийного цикла;
\item прочитанный кадр сохраняется в \emph{ReadBuffer}, откуда позже будет извлечен корутиной \emph{DetectionPoller};
\item затем формируется сообщение с запросом на распознавание, и далее оно отправляется на обработку одному из рабочих.
После отправки кадра \emph{Reader} сразу переходит к чтению следующего кадра, не дожидаясь результатов распознавания;
\item получив кадр рабочий производит распознавание объектов и отправляет планировщику сообщение с результатами;
\item корутина \emph{DetectionPoller} активируется в момент получения одного из результатов распознавания. После 
происходит упорядочивание уже полученных кадров \emph{sort\_frames}, согласно алгоритму сохранения кадров, описанному 
ранее. Затем кадры уже в правильном порядке записываются в \emph{WriteBuffer};
\item при получении кадра корутина \emph{Writer} отображает на кадре ограничивающие рамки и название классов объектов, 
после кадр записывается на диск. Чтобы не блокировать поток событийного цикла также были реализованы два класса 
\emph{AsyncDetectionWriter} и \emph{AsyncFrameWriter}.
\end{enumerate}

\clearpage
